{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41ceec-14f7-42e6-9f85-f29cab16a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readability import Readability\n",
    "from datasets import Dataset\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import json\n",
    "import re\n",
    "\n",
    "def create_df(base_path):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for file in Path(base_path).iterdir():\n",
    "        if \"input\" in file.stem:\n",
    "            with Path(file).open('r') as file:\n",
    "                 inputs.extend([json.loads(line) for line in file])\n",
    "        elif \"output\" in file.stem:\n",
    "            with Path(file).open('r') as file:\n",
    "                 outputs.extend([json.loads(line) for line in file])\n",
    "    \n",
    "    inputs_df = pd.DataFrame(inputs)\n",
    "    outputs_df = pd.DataFrame(outputs)\n",
    "    merged_df = pd.merge(inputs_df, outputs_df)\n",
    "    merged_df.drop(columns=[\"method\", \"url\", \"id\", \"error\"], inplace=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd732acc-db5c-4ade-b8c3-836cd3ad371b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Creating text sources from complexify phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08d786-c5b5-4c1e-83d4-ca8e41d09fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"../data/OAI/complexify/batch_output.jsonl\").open('r') as file:\n",
    "     complexify_outputs = [json.loads(line) for line in file]\n",
    "\n",
    "for response_dict in complexify_outputs:\n",
    "    drug_name = response_dict[\"custom_id\"].split(\"-complexify\")[0]\n",
    "    complexified_text = response_dict[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    with Path(f\"../data/background_information_data/drug_data/Wiki_complexified/{drug_name}.txt\").open(\"w\") as file:\n",
    "        file.write(complexified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be2ca5-b64f-4a93-a005-5ffff0acceb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Measuring readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eb542a-4fd1-4f2b-946e-dfd4a8598ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "ddi_subset = pd.read_csv(\"../data/mined_data/final_DDI.csv\")\n",
    "all_drugs = set(ddi_subset[\"drug_1_name\"].unique()).union(set(ddi_subset[\"drug_2_name\"].unique()))\n",
    "\n",
    "orig_tokens = []\n",
    "orig_readability = []\n",
    "comp_tokens = []\n",
    "comp_readability = []\n",
    "for drug in all_drugs:\n",
    "    drug_orig = Path(f\"../data/background_information_data/drug_data/Wiki/{drug}.txt\")\n",
    "    drug_comp = Path(f\"../data/background_information_data/drug_data/Wiki_complexified/{drug}.txt\")\n",
    "    if drug_orig.exists() and drug_comp.exists():\n",
    "        with drug_orig.open(\"r\") as file:\n",
    "            orig_text = file.read()\n",
    "            orig_tokens.append(len(gpt_tokenizer.encode(orig_text)))\n",
    "            orig_readability.append(Readability(orig_text).gunning_fog().score)\n",
    "        with drug_comp.open(\"r\") as file:\n",
    "            comp_text = file.read()\n",
    "            comp_tokens.append(len(gpt_tokenizer.encode(comp_text)))\n",
    "            comp_readability.append(Readability(comp_text).gunning_fog().score)\n",
    "\n",
    "print(f\"Avg. Original Tokens: {sum(orig_tokens)/len(orig_tokens)} | Avg. Original Readability: {sum(orig_readability)/len(orig_readability)}\")\n",
    "print(f\"Avg. Complex Tokens: {sum(comp_tokens)/len(comp_tokens)} | Avg. Complex Readability: {sum(comp_readability)/len(comp_readability)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceabd06-df67-4427-b0eb-2aaaf4fb0a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Creating Molecular interaction table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79f053-55eb-4133-8199-b468209f1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = create_df(\"../data/OAI/molecular_interactions/\")\n",
    "\n",
    "final_rows = []\n",
    "for row in merged_df.itertuples():\n",
    "    drug_1, drug_2 = row.custom_id.split(\"-\")[:2]\n",
    "    SMILES_1, SMILES_2 = [x[-1].strip() for x in re.findall(r\"(SMILES )(\\d: )(.*)\", row.body[\"messages\"][1][\"content\"])]\n",
    "    response = row.response[\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    pattern = r\"^(?P<interaction_field>\\*{0,2}INTERACTION\\*{0,2}):\\s*(?P<interaction>.*?)\\n(?P<mechanism_field>\\*{0,2}MECHANISM\\*{0,2}):\\s*(?P<mechanism>.*(?:\\n(?!\\*{0,2}(EVIDENCE|SEVERITY)\\*{0,2}:).*)*)\\n(?P<evidence_field>\\*{0,2}EVIDENCE\\*{0,2}):\\s*(?P<evidence>.*(?:\\n(?!\\*{0,2}SEVERITY\\*{0,2}:).*)*)\\n(?P<severity_field>\\*{0,2}SEVERITY\\*{0,2}):\\s*(?P<severity>.*)$\"\n",
    "    matches = re.search(pattern, response, re.DOTALL | re.MULTILINE | re.IGNORECASE)\n",
    "    \n",
    "    interaction = matches.group('interaction').strip()\n",
    "    mechanism = matches.group('mechanism').strip()\n",
    "    evidence = matches.group('evidence').strip()\n",
    "    if interaction == \"None\": # None is not the \"type\" here. Thus, not using if interaction is None.\n",
    "        continue\n",
    "    severity = matches.group('severity').strip()\n",
    "    \n",
    "    final_rows.append((drug_1, drug_2, SMILES_1, SMILES_2, interaction, mechanism, evidence, severity))\n",
    "\n",
    "pd.DataFrame(final_rows, columns=[\"drug_1_name\", \"drug_2_name\", \"drug_1_SMILES\", \"drug_2_SMILES\", \n",
    "                                  \"molecular_interaction\", \n",
    "                                  \"mechanism\", \n",
    "                                  \"evidence\", \n",
    "                                  \"severity\"]).to_csv(\"../data/OAI/molecular_interactions/molecular_interactions_df.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6bcf9-552d-4d78-910f-d803af34b492",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Assembling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b56745-2489-492d-b154-6402ca5c0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_QA_df(base_df, label):\n",
    "    final_rows = []\n",
    "    for row in base_df.itertuples(index=False):\n",
    "        entity_pair = \"-\".join(list(filter(lambda x: x not in [\"DDI\", \"DPI\", \"Bio\", \"Mol\", \"1_hop\", \"2_hop\", \"3_hop\"], row.custom_id.split(\"-\"))))\n",
    "        question_background = row.body[\"messages\"][1][\"content\"]\n",
    "        response = re.sub(r'\\*{1,2}(.*?)\\*{1,2}', r'\\1', row.response[\"body\"][\"choices\"][0][\"message\"][\"content\"])\n",
    "        pattern = r\"Question:\\s*(.*?)\\s*Answer:\\s*(.*)\"\n",
    "        match = re.search(pattern, response, re.DOTALL)\n",
    "        question = match.group(1).strip()\n",
    "        answer = match.group(2).strip()\n",
    "        final_rows.append((entity_pair, question_background, question, answer, label))\n",
    "    return pd.DataFrame(final_rows, columns=[\"Entities\", \"Question_Background\", \"Question\", \"Answer\", \"Label\"])\n",
    "\n",
    "df1 = create_QA_df(create_df(\"../data/OAI/Questions/DDI/Bio/1_hop/\"), \"DDI_Bio_1_hop\")\n",
    "df2 = create_QA_df(create_df(\"../data/OAI/Questions/DDI/Bio/2_hop/\"), \"DDI_Bio_2_hop\")\n",
    "df3 = create_QA_df(create_df(\"../data/OAI/Questions/DDI/Bio/3_hop/\"), \"DDI_Bio_3_hop\")\n",
    "\n",
    "df4 = create_QA_df(create_df(\"../data/OAI/Questions/DDI/Mol/1_hop/\"), \"DDI_Mol_1_hop\")\n",
    "df5 = create_QA_df(create_df(\"../data/OAI/Questions/DDI/Mol/2_hop/\"), \"DDI_Mol_2_hop\")\n",
    "df6 = create_QA_df(create_df(\"../data/OAI/Questions/DDI/Mol/3_hop/\"), \"DDI_Mol_3_hop\")\n",
    "\n",
    "df7 = create_QA_df(create_df(\"../data/OAI/Questions/DPI/1_hop/\"), \"DPI_1_hop\")\n",
    "df8 = create_QA_df(create_df(\"../data/OAI/Questions/DPI/2_hop/\"), \"DPI_2_hop\")\n",
    "df9 = create_QA_df(create_df(\"../data/OAI/Questions/DPI/3_hop/\"), \"DPI_3_hop\")\n",
    "\n",
    "final_QA_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9])\n",
    "final_QA_df.to_csv(\"../data/OAI/Questions/all_questions.csv\", index=False)\n",
    "\n",
    "# Creating our dataset for HF\n",
    "dataset = Dataset.from_pandas(final_QA_df, preserve_index=False)\n",
    "dataset = dataset.class_encode_column(\"Label\")\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"Label\", seed=42)\n",
    "dataset[\"train\"].to_csv(\"../dataset_for_hf/train.csv\")\n",
    "\n",
    "val_test_ds = dataset[\"test\"]\n",
    "val_test_ds = val_test_ds.train_test_split(test_size=0.5, stratify_by_column=\"Label\", seed=42)\n",
    "\n",
    "# Saving \"test\" as validation since it has more samples. The \"test\"/\"train\" labels are arbitrary.\n",
    "val_test_ds[\"test\"].to_csv(\"../dataset_for_hf/validation.csv\")\n",
    "val_test_ds[\"train\"].to_csv(\"../dataset_for_hf/test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
