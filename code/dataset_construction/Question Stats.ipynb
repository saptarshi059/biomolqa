{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10b395-2ca5-4dcd-b4dd-c79ca79a1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexicalrichness import LexicalRichness\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "gpt_tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "question_df = pd.read_csv(\"../data/OAI/Questions/all_questions.csv\")\n",
    "all_questions = question_df.Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c7cc7-6cb6-4f6d-b434-f8c8d27a2c52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Question Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa0380-a288-4afa-940c-03f5773af197",
   "metadata": {},
   "outputs": [],
   "source": [
    "toks = [len(gpt_tokenizer.encode(ques)) for ques in all_questions]\n",
    "print(f\"Average question tokens: {np.mean(toks)}\")\n",
    "\n",
    "n, bins, patches = plt.hist(toks)\n",
    "norm = plt.Normalize(min(n), max(n))\n",
    "for i, patch in enumerate(patches):\n",
    "    patch.set_facecolor(plt.cm.viridis(norm(n[i])))\n",
    "    plt.text(patch.get_x() + patch.get_width() / 2, patch.get_height(), f\"{int(n[i])}\", ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(bins)\n",
    "plt.savefig(\"../figures/for paper/q_len_dist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256ae51-f5b9-4a3d-bcef-548c27649345",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Text-to-Token Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8aa2fe-f312-4207-a380-c1590deb2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs = [LexicalRichness(ques).ttr for ques in all_questions]\n",
    "print(f\"Average TTR: {np.mean(ttrs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64946055-8c24-41ce-b827-08779dfc1e2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88c16a-b737-480a-9133-c21901a1dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(token_list, base=2):\n",
    "    values, counts = np.unique(token_list, return_counts=True)\n",
    "    probs = counts / counts.sum()\n",
    "    return entropy(probs, base=base)\n",
    "\n",
    "batch_encoded_questions = gpt_tokenizer.encode_ordinary_batch(all_questions)\n",
    "avg_entropy = np.round(np.mean([shannon_entropy(tok_list) for tok_list in batch_encoded_questions]), 2)\n",
    "print(f\"Average Entropy: {avg_entropy}\")\n",
    "\n",
    "max_entropy = np.log2(len(set([len(x) for x in batch_encoded_questions])))\n",
    "print(f\"Maximum possibe entropy for the questions: {np.round(max_entropy.item(),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072f88d-5275-48ce-8683-749cc519ed02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dependency Parse Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928c714-17b9-4851-8c5a-93ad865fbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on Colab since it involves a transformer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "def dependency_tree_depth(root):\n",
    "    \"\"\"Calculate the depth of a dependency parse tree starting from the root.\"\"\"\n",
    "    if not list(root.children):\n",
    "        return 1\n",
    "    return 1 + max(dependency_tree_depth(child) for child in root.children)\n",
    "\n",
    "depths = []\n",
    "for question in tqdm(all_questions):\n",
    "  doc = nlp(question)\n",
    "  root = [token for token in doc if token.head == token][0]\n",
    "  depths.append(dependency_tree_depth(root))\n",
    "\n",
    "print(f\"Average dependency tree depth: {np.round(np.mean(depths), 2)}\") #10.86"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d12fa-755c-41b8-b045-a4af55572eb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Question Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb2d15-8ea4-4614-b8cb-de8a464b380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "which = []\n",
    "what = []\n",
    "identify = []\n",
    "for question in all_questions:\n",
    "    if re.search(\"which\", question, re.IGNORECASE):\n",
    "        which.append(question)\n",
    "    elif re.search(\"what\", question, re.IGNORECASE):\n",
    "        what.append(question)\n",
    "    elif re.search(\"identify\", question, re.IGNORECASE):\n",
    "        identify.append(question)\n",
    "\n",
    "print(f\"Number of 'Which' questions: {len(which)}\\nNumber of 'What' questions: {len(what)}\\nNumber of 'Identify' questions: {len(identify)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270aa6f7-5f8c-43d9-b0a1-bc8f1b4ae64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for entity leak\n",
    "c=0\n",
    "for row in question_df.itertuples():\n",
    "    all_ents = row.Entities.split(\"-\")\n",
    "    if len(all_ents) > 4:\n",
    "        all_ents = all_ents[:3] + [\"-\".join(all_ents[3:])]\n",
    "    for ent in all_ents:\n",
    "        if re.search(rf\"\\b{ent}\\b\", row.Question, re.IGNORECASE):\n",
    "            c+=1\n",
    "            break\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d947c83-3009-4a16-9adb-276f6bc66b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for SMILES leak\n",
    "for row in question_df.itertuples():\n",
    "    if \"=\" in row.Question:\n",
    "        print(row.Question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
