{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d7fec83-62af-491b-886f-d2d6e33fd9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5b649b-920d-4683-a8be-160bfa30228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_subset = pd.read_csv(\"../mined_data/DDI_subset.csv\")\n",
    "dpi_subset = pd.read_csv(\"../mined_data/DPI_subset.csv\")\n",
    "ppi_subset = pd.read_csv(\"../mined_data/PPI_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b565b534-2d09-4476-ac42-df16404ebdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308, 331, 210)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ddi_subset), len(dpi_subset), len(ppi_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d04510cd-209f-47f1-bdab-8f77d01f1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "drug_data_path = Path(\"../background_information_data/drug_data\")\n",
    "protein_data_path = Path(\"../background_information_data/protein_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e40edc5c-095e-4d3d-81ee-7a82cf0f46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = []\n",
    "for row in dpi_subset.itertuples():\n",
    "    with Path(drug_data_path / f\"{row.drug_name}.txt\").open(\"r\") as drug_data_file:\n",
    "        drug_data = max(drug_data_file.readlines(), key=len)\n",
    "\n",
    "    with Path(protein_data_path / f\"{row.protein_name}.txt\").open(\"r\") as protein_data_file:\n",
    "        protein_data = max(protein_data_file.readlines(), key=len)\n",
    "\n",
    "    if row.mode != row.action:\n",
    "        triple = f\"{row.drug_name} - {row.mode} and {row.action} - {row.protein_name}\"\n",
    "    else:\n",
    "        triple = f\"{row.drug_name} - {row.mode} - {row.protein_name}\"\n",
    "    \n",
    "    prompt = f\"\"\"I am providing you with a drug-protein interaction as a knowledge graph triple along with their associated background information. \n",
    "I would like you to write 5 multiple-choice question-answer pairs. Each question must be a created by combining all of the provided information. \n",
    "Please structure your output as follows,\n",
    "Question: <question text>\n",
    "Choices: <answer choices labelled as (a), (b), (c), (d)>\n",
    "Correct choice: <among (a), (b), (c) or (d)>\n",
    "\n",
    "Drug-Protein interaction triple: {triple}\n",
    "\n",
    "Drug name: {row.drug_name} \n",
    "Drug information: {drug_data.strip()}\n",
    "\n",
    "Protein name: {row.protein_name}\n",
    "Protein information: {protein_data.strip()}\n",
    "\"\"\"\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbe5409-0390-4755-a724-3a3387e27fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "def generate_response(messages):\n",
    "    input_text = \"\"\n",
    "    for message in messages:\n",
    "        input_text += f\"{message['role']}: {message['content']}\\n\"\n",
    "    \n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a question answering AI assistant. You are provided with a question and choices for that question. I would like you tell me what the correct answer is after explaining your reason. Please provide your answer like,\\nanswer: a\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Question: What is the significance of HRH1 in the context of antimicrobial research?\n",
    "Choices:\n",
    "(a) HRH1 activation enhances the immune response to bacterial infections.\n",
    "(b) HRH1 inhibition has been linked to reducing biofilm formation in Staphylococcus aureus.\n",
    "(c) HRH1 promotes bacterial resistance, making it a target for pro-bacterial therapies.\n",
    "(d) HRH1 is primarily involved in viral infections and has no relevance to bacteria.\"\"\"},\n",
    "]\n",
    "\n",
    "generate_response(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
