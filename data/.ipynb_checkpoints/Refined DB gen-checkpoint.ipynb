{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47838ed0-fbf9-479d-be25-8396416e5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from collections import defaultdict\n",
    "import plotly.graph_objects as go\n",
    "from Bio import Entrez, Medline\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pubchempy as pcp\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import signal\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Set email address (required for NCBI API usage)\n",
    "Entrez.email = 'sks6765@psu.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea01064-aeba-438b-b03d-260fe35fc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_viz(dataframe, column1, column2, label=1):\n",
    "    # Creating an interactive graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add edges to the graph\n",
    "    for index, row in dataframe.iterrows():\n",
    "        G.add_edge(row[column1], row[column2], label=row[label] if label != 1 else 1)\n",
    "    \n",
    "    # Add edge labels\n",
    "    edge_labels = {(u, v): d['label'] for u, v, d in G.edges(data=True)}\n",
    "    nx.set_edge_attributes(G, edge_labels, 'label')\n",
    "    \n",
    "    # Position nodes using spring layout\n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    # Extract node and edge information\n",
    "    node_x = [pos[node][0] for node in G.nodes()]\n",
    "    node_y = [pos[node][1] for node in G.nodes()]\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_text = []\n",
    "    for edge in G.edges():\n",
    "        source, target = edge\n",
    "        x0, y0 = pos[source]\n",
    "        x1, y1 = pos[target]\n",
    "        edge_x.append(x0)\n",
    "        edge_x.append(x1)\n",
    "        edge_x.append(None)\n",
    "        edge_y.append(y0)\n",
    "        edge_y.append(y1)\n",
    "        edge_y.append(None)\n",
    "        edge_text.append(G.get_edge_data(*edge)['label'])  # Use existing edge labels\n",
    "    \n",
    "    # Create a Plotly figure\n",
    "    fig = go.Figure(data=[go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        mode='lines',\n",
    "        line_shape='spline',\n",
    "        opacity=0.5,\n",
    "        hoverinfo='none'\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=node_x,\n",
    "        y=node_y,\n",
    "        mode='markers',\n",
    "        hoverinfo='text',\n",
    "        hovertext=[f'Node {node}' for node in G.nodes()]\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=[(pos[edge[0]][0] + pos[edge[1]][0]) / 2 for edge in G.edges()],\n",
    "        y=[(pos[edge[0]][1] + pos[edge[1]][1]) / 2 for edge in G.edges()],\n",
    "        mode='text',\n",
    "        text=edge_text,\n",
    "        textposition='middle center',\n",
    "        hoverinfo='none'\n",
    "    )])\n",
    "    \n",
    "    # Customize the layout\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        hovermode='x',\n",
    "        margin=dict(b=20, l=5, r=5, t=40),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "    \n",
    "    # Display the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb589ef-f268-4be7-81fd-dabe969a12d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DDI Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41a15e-93ba-4add-90c6-d568f3fd4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi = pd.read_csv(\"bio-decagon-combo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb7bbc-35d7-4602-95ec-987c7ce468f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutError\n",
    "\n",
    "def CID_information(CID: int, timeout: int = 5):\n",
    "\n",
    "    # Set the signal handler\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "\n",
    "    # Set the alarm\n",
    "    signal.alarm(timeout)\n",
    "\n",
    "    try:\n",
    "        cleaned_cid = int(re.sub(r\"CID[m|s]*0*\", \"\", CID))\n",
    "        compound = pcp.Compound.from_cid(cleaned_cid)\n",
    "        try:\n",
    "            compound_name = compound.synonyms[0]\n",
    "        except:\n",
    "            compound_name = compound.iupac_name\n",
    "        return (compound_name, compound.canonical_smiles)\n",
    "    except TimeoutError:\n",
    "        print(\"Timeout: Function took too long to complete.\")\n",
    "        return None\n",
    "    finally:\n",
    "        # Disable the alarm\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167663fb-85d3-411f-90ad-84793bb55d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=85\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Creating the graph from the ddi dataframe\n",
    "G = nx.from_pandas_edgelist(ddi, 'STITCH 1', 'STITCH 2')\n",
    "\n",
    "# Get the largest connected component\n",
    "largest_component = max(nx.connected_components(G), key=len)\n",
    "\n",
    "# Sample nodes from the largest component\n",
    "sample_size = 300\n",
    "sample_nodes = np.random.choice(list(largest_component), size=sample_size, replace=False)\n",
    "\n",
    "# Get the subgraph induced by the sampled nodes\n",
    "subgraph = G.subgraph(sample_nodes)\n",
    "\n",
    "# Convert the subgraph back to a DataFrame\n",
    "sampled_df = nx.to_pandas_edgelist(subgraph).sample(n=2000, random_state=random_state)\n",
    "\n",
    "sampled_df.rename(columns={\"source\": \"STITCH 1\", \"target\": \"STITCH 2\"}, inplace=True)\n",
    "\n",
    "# Merging the sampled df with base ddi to get the side effect names\n",
    "sampled_df = pd.merge(sampled_df, ddi).drop_duplicates(subset=[\"STITCH 1\", \"STITCH 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67c985-bbe0-44b1-85cd-ea1d5282e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check the output\n",
    "\n",
    "# Visualizing sampled_df as a graph to see that there are no disconnected edges\n",
    "create_graph_viz(sampled_df, \"STITCH 1\", \"STITCH 2\")\n",
    "\n",
    "all_drugs_according_to_df = len(set(sampled_df['STITCH 1'].to_list()).union(set(sampled_df['STITCH 2'].to_list())))\n",
    "\n",
    "# Verify that you get the same value from the sampled_df as a graph\n",
    "G = nx.from_pandas_edgelist(sampled_df, 'STITCH 1', 'STITCH 2')\n",
    "number_of_drug_nodes = len(G.nodes())\n",
    "\n",
    "assert all_drugs_according_to_df == number_of_drug_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7109eb20-1e03-4d05-b0d6-56951c391fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(all_information):\n",
    "    pd.DataFrame(all_information, columns=[\"drug_1_CID\", \"drug_1_name\", \"drug_1_SMILES\", \"relationship\", \"drug_2_CID\", \"drug_2_name\", \n",
    "                                               \"drug_2_SMILES\"]).to_csv(\"DDI_subset.csv\", index=False)\n",
    "\n",
    "number_of_ddis_to_retain = 300\n",
    "all_information = []\n",
    "\n",
    "for idx, sample in tqdm(enumerate(sampled_df.itertuples(index=False))):    \n",
    "    drug_1_CID = sample[0]\n",
    "    drug_2_CID = sample[1]\n",
    "    relationship = sample[3]\n",
    "\n",
    "    drug_1_info = CID_information(drug_1_CID)\n",
    "    drug_2_info = CID_information(drug_2_CID)\n",
    "    \n",
    "    try:\n",
    "        # I want the drug name to not include any numbers or brackets, i.e., only keep regular words.\n",
    "        if (not re.search(r\"[\\W\\d]|(sulfate)\", drug_1_info[0])) and (not re.search(r\"[\\W\\d]|(sulfate)\", drug_2_info[0])):\n",
    "\n",
    "            # This ensures that when I am retrieving the background information, I will get 20 pubmed hits.\n",
    "            drug1_query = f\"{drug_1_info[0]} AND hasabstract AND Humans AND (AD OR AE OR PK OR PD OR CO OR TU OR DE)\"\n",
    "            with Entrez.esearch(db='pubmed', term=drug1_query, retmax=20, sort=\"relevance\") as handle:\n",
    "                paper_list_drug1 = Entrez.read(handle)[\"IdList\"]\n",
    "    \n",
    "            drug2_query = f\"{drug_2_info[0]} AND hasabstract AND Humans AND (AD OR AE OR PK OR PD OR CO OR TU OR DE)\"\n",
    "            with Entrez.esearch(db='pubmed', term=drug2_query, retmax=20, sort=\"relevance\") as handle:\n",
    "                paper_list_drug2 = Entrez.read(handle)[\"IdList\"]\n",
    "            \n",
    "            if len(paper_list_drug1) == 20 and len(paper_list_drug2) == 20:            \n",
    "                all_information.append((drug_1_CID, drug_1_info[0], drug_1_info[1], relationship, drug_2_CID, drug_2_info[0], drug_2_info[1]))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # timeout after 50 API calls.\n",
    "    if (idx % 50 == 0) and (idx != 0):\n",
    "        print(f\"Samples collected so far: {len(all_information)}. Saving checkpoint and cooling down ...\")\n",
    "        save_dataframe(all_information)\n",
    "        time.sleep(5)        \n",
    "    \n",
    "    if len(all_information) == number_of_ddis_to_retain:\n",
    "        print(\"Necessary number of DDIs obtained... exiting\")\n",
    "        save_dataframe(all_information)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdecf766-2dc6-4c8a-9c41-96070eb78024",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DPI Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41580f9b-51b2-4eea-94fc-4e5088bd9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddi_subset = pd.read_csv(\"DDI_subset.csv\")\n",
    "dpi = pd.read_csv(\"bio-decagon-targets-all.csv\")\n",
    "actions_subset = pd.read_csv(\"action_subset.csv\")\n",
    "\n",
    "all_drugs_CID = set(ddi_subset[\"drug_1_CID\"].to_list()).union(set(ddi_subset[\"drug_2_CID\"].to_list()))\n",
    "\n",
    "dpi_subset = dpi.query(\"STITCH in @all_drugs_CID\")\n",
    "\n",
    "# Converting PubChem CID to STITCH CIDs (singular element) (https://www.biostars.org/p/155342/)\n",
    "dpi_subset.loc[:, 'STITCH'] = dpi_subset['STITCH'].str.replace('CID0', 'CIDs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc16bca-f4eb-45ed-b9e3-82ad96b39dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I'm doing these following steps to retain the largest connected subgraph & remove disconnected components.\n",
    "'''\n",
    "\n",
    "# Creating the graph from the ddi dataframe\n",
    "G = nx.from_pandas_edgelist(dpi_subset, 'STITCH', 'Gene')\n",
    "\n",
    "# Get the largest connected component\n",
    "largest_component = max(nx.connected_components(G), key=len)\n",
    "\n",
    "subgraph = G.subgraph(largest_component)\n",
    "dpi_subset = nx.to_pandas_edgelist(subgraph)\n",
    "\n",
    "condition = dpi_subset[\"source\"].apply(lambda x: isinstance(x, (int, float)))\n",
    "dpi_subset.loc[condition, ['source', 'target']] = dpi_subset.loc[condition, ['target', 'source']].values\n",
    "dpi_subset.rename(columns={\"source\": \"STITCH\", \"target\":\"Gene\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce48d8-0fd8-44b0-b678-935f31378956",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_list = []\n",
    "for row in tqdm(dpi_subset.itertuples()):  \n",
    "    # Retrieving protein data from the given gene ID\n",
    "    url = f\"https://string-db.org/api/json/get_string_ids?identifiers={row.Gene}&species=9606\"\n",
    "    try:\n",
    "        response = requests.get(url).json()[0]\n",
    "        string_id = (response[\"stringId\"], response[\"preferredName\"], response[\"annotation\"], row.Gene)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    search_list.append((row.STITCH, string_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc4a8f-0ccd-459a-8e08-04a64af94e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pairs = list(zip([x[0] for x in search_list], [x[1][0] for x in search_list]))\n",
    "r = actions_subset[actions_subset.apply(lambda x: (x[\"item_id_a\"], x[\"item_id_b\"]) in set(target_pairs), axis=1)]\n",
    "\n",
    "search_df = pd.DataFrame({\"cid\": [x[0] for x in search_list], \"protein_number\": [x[1][0] for x in search_list], \n",
    "                          \"protein_name\": [x[1][1] for x in search_list], \"protein_desc\": [x[1][2] for x in search_list],\n",
    "                          \"gene\": [x[1][3] for x in search_list]})\n",
    "\n",
    "# Need to drop duplicates because of \"a is acting\" column. That is, the same entry can be repeated twice because of \"a is acting\"\n",
    "r = pd.merge(r, search_df, left_on=[\"item_id_a\", \"item_id_b\"], right_on=[\"cid\", \"protein_number\"], \n",
    "             how=\"inner\").drop(columns=[\"item_id_a\", \"item_id_b\", \"action\", \"a_is_acting\", \"score\"]).drop_duplicates()\n",
    "\n",
    "r[\"cid\"] = r[\"cid\"].str.replace(\"CIDs\", \"CID0\") # Going back to PubChem CID to be compatible with other DDI\n",
    "r.to_csv(\"DPI_subset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
